{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.7.0 detected. Last version known to be fully compatible is 2.3.1 .\n",
      "WARNING:root:Keras version 2.7.0 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from seq2seq_util import Seq2SeqBatchGenerator\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Input, LSTM, Masking\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab_size = 101\n",
    "out_vocab_size = 87\n",
    "latent_dim = 256\n",
    "\n",
    "coreml_enc_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "coreml_enc_lstm = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")\n",
    "coreml_enc_out, _, _ = coreml_enc_lstm(coreml_enc_in)\n",
    "\n",
    "coreml_encoder_model = Model(coreml_enc_in, coreml_enc_out)\n",
    "coreml_encoder_model.output_layers = coreml_encoder_model._output_layers\n",
    "\n",
    "coreml_encoder_model.load_weights(\"Es2EnCharEncoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 18.31 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 23403.85 ops/s]\n",
      "WARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 40/40 [00:00<00:00, 5701.11 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 26063.14 ops/s]\n",
      "WARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 40/40 [00:00<00:00, 2422.32 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 41/41 [00:00<00:00, 708.68 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 3523.37 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 318.03 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 6533.18 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 24/24 [00:00<00:00, 700.87 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 66/66 [00:00<00:00, 1463.84 ops/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "from keras.layers.normalization.layer_normalization import *\n",
    "from keras.layers.normalization.batch_normalization import *\n",
    "\n",
    "coreml_encoder = coremltools.converters.convert(\n",
    "    coreml_encoder_model,\n",
    "    input_names=\"encodedSeq\",\n",
    "    output_names=\"ignored\")\n",
    "\n",
    "coreml_encoder.save(\"Es2EnCharEncoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_dec_in = Input(shape=(None, out_vocab_size))\n",
    "\n",
    "coreml_dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "coreml_dec_lstm_out, _, _ = coreml_dec_lstm(coreml_dec_in)\n",
    "coreml_dec_dense = Dense(out_vocab_size, activation=\"softmax\")\n",
    "coreml_dec_out = coreml_dec_dense(coreml_dec_lstm_out)\n",
    "\n",
    "coreml_decoder_model = Model(coreml_dec_in, coreml_dec_out)\n",
    "coreml_decoder_model.output_layers = coreml_decoder_model._output_layers\n",
    "\n",
    "coreml_decoder_model.load_weights(\"Es2EnCharDecoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 18.49 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 27490.76 ops/s]\n",
      "WARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 40/40 [00:00<00:00, 6522.26 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 14/14 [00:00<00:00, 27235.74 ops/s]\n",
      "WARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 40/40 [00:00<00:00, 4210.94 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 61/61 [00:00<00:00, 451.13 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 1750.48 passes/s]\n",
      "Running MIL Clean up passes: 100%|██████████| 8/8 [00:00<00:00, 2537.96 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 3718.35 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 24/24 [00:00<00:00, 778.51 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 80/80 [00:00<00:00, 1853.27 ops/s]\n"
     ]
    }
   ],
   "source": [
    "coreml_decoder = coremltools.converters.convert(\n",
    "    coreml_decoder_model,\n",
    "    input_names=\"encodedChar\",\n",
    "    output_names=\"nextCharProbs\")\n",
    "\n",
    "coreml_decoder.save(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.models.neural_network import quantization_utils\n",
    "\n",
    "def convert_to_fp16(mlmodel_filename):\n",
    "    model_fp32 = coremltools.models.MLModel(mlmodel_filename)\n",
    "    spec_16bit = quantization_utils.quantize_weights(model_fp32, nbits=16)\n",
    "    coremltools.utils.save(spec_16bit, f\"{mlmodel_filename}16Bit.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个单元格我也不知道为什么又没有`save`这个了，不过这步~~应该~~也只是为了减小体积，我就跳过好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Quantizing layer tf_make_list_0_condition_re_initialize\n",
      "Quantizing layer tf_make_list_0_condition\n",
      "Quantizing layer model/encoder_lstm/PartitionedCall/while_renamed\n",
      "Quantizing layer model/encoder_lstm/PartitionedCall/while/while_body_1152/while/MatMul_1\n",
      "Quantizing layer model/encoder_lstm/PartitionedCall/while/while_body_1152/while/MatMul\n",
      "Quantizing layer model/encoder_lstm/PartitionedCall/while_1_condition_re_initialize\n",
      "Quantizing layer model/encoder_lstm/PartitionedCall/while_1_condition\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'coremltools.models.utils' has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/f8dm9__n0w1bt_dx412zv5jh0000gn/T/ipykernel_6688/1625645674.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_to_fp16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Es2EnCharEncoder.mlmodel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconvert_to_fp16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Es2EnCharDecoder.mlmodel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gh/f8dm9__n0w1bt_dx412zv5jh0000gn/T/ipykernel_6688/1377107800.py\u001b[0m in \u001b[0;36mconvert_to_fp16\u001b[0;34m(mlmodel_filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_fp32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mspec_16bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantization_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoremltools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_16bit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{mlmodel_filename}16Bit.mlmodel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'coremltools.models.utils' has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "convert_to_fp16(\"Es2EnCharEncoder.mlmodel\")\n",
    "convert_to_fp16(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面单元格移步原notebook执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_token2int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/f8dm9__n0w1bt_dx412zv5jh0000gn/T/ipykernel_6688/4095735616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"esCharToInt.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_token2int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intToEnChar.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_int2token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_token2int' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"esCharToInt.json\", \"w\") as f:\n",
    "    json.dump(in_token2int, f)\n",
    "with open(\"intToEnChar.json\", \"w\") as f:\n",
    "    json.dump(out_int2token, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70fd0a885b79e870c4dcdc6bf2728a3f7cb49cd72679c2ee6f0dd44ee4fee99c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('turienv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
