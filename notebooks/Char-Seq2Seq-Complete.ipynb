{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset. It contains translations from English to Spanish, so swap the order of the phrases. Also add `\\t` and `\\n` as the start and stop tokens in the target sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \"\\t\"\n",
    "stop_token = \"\\n\"\n",
    "\n",
    "with open(\"data/spa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    samples = f.read().split(\"\\n\")\n",
    "\n",
    "samples = [sample.strip().split(\"\\t\")\n",
    "           for sample in samples if len(sample.strip()) > 0]\n",
    "\n",
    "samples = [(es, start_token + en + stop_token)\n",
    "           for en, es in samples if len(es) < 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99423"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ve.', '\\tGo.\\n'), ('Vete.', '\\tGo.\\n'), ('Vaya.', '\\tGo.\\n'), ('Váyase.', '\\tGo.\\n'), ('Hola.', '\\tHi.\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(samples[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, valid_samples = train_test_split(samples, train_size=.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the training vocabulary. Those are the only tokens you can trust the model will know how to handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 101\n",
      "Output vocab size: 87\n"
     ]
    }
   ],
   "source": [
    "in_vocab = set()\n",
    "out_vocab = set()\n",
    "\n",
    "for in_seq, out_seq in train_samples:\n",
    "    in_vocab.update(in_seq)\n",
    "    out_vocab.update(out_seq)\n",
    "    \n",
    "in_vocab_size = len(in_vocab)\n",
    "out_vocab_size = len(out_vocab)\n",
    "print(\"Input vocab size:\", in_vocab_size)\n",
    "print(\"Output vocab size:\", out_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '°', 'º', '»', '¿', 'Á', 'É', 'Ó', 'Ú', 'á', 'è', 'é', 'í', 'ñ', 'ó', 'ö', 'ú', 'ü', 'ś', 'с', '—', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(in_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '$', '%', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'á', 'ã', 'è', 'é', 'ö', '‘', '’', '₂', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(out_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through validation set and remove any tokens not present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_samples = []\n",
    "for in_seq, out_seq in valid_samples:\n",
    "    tmp_in_seq = [c for c in in_seq if c in in_vocab]\n",
    "    tmp_out_seq = [c for c in out_seq if c in out_vocab]\n",
    "\n",
    "    tmp_samples.append((\"\".join(tmp_in_seq), \"\".join(tmp_out_seq)))\n",
    "    \n",
    "valid_samples = tmp_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build sequence-to-sequence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, Masking\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 21:41:23.682200: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "encoder_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "encoder_mask = Masking(name=\"encoder_mask\")(encoder_in)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, recurrent_dropout=0.3, name=\"encoder_lstm\")\n",
    "_, encoder_h, encoder_c = encoder_lstm(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_in = Input(shape=(None, out_vocab_size), name=\"decoder_in\")\n",
    "\n",
    "decoder_mask = Masking(name=\"decoder_mask\")(decoder_in)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
    "                    dropout=0.2, recurrent_dropout=0.3, name=\"decoder_lstm\")\n",
    "decoder_lstm_out, _, _ = decoder_lstm(decoder_mask, initial_state=[encoder_h, encoder_c])\n",
    "decoder_dense = Dense(out_vocab_size, activation=\"softmax\", name=\"decoder_out\")\n",
    "decoder_out = decoder_dense(decoder_lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = Model([encoder_in, decoder_in], decoder_out)\n",
    "seq2seq_model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_in (InputLayer)        [(None, None, 101)]  0           []                               \n",
      "                                                                                                  \n",
      " decoder_in (InputLayer)        [(None, None, 87)]   0           []                               \n",
      "                                                                                                  \n",
      " encoder_mask (Masking)         (None, None, 101)    0           ['encoder_in[0][0]']             \n",
      "                                                                                                  \n",
      " decoder_mask (Masking)         (None, None, 87)     0           ['decoder_in[0][0]']             \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        366592      ['encoder_mask[0][0]']           \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 256),  352256      ['decoder_mask[0][0]',           \n",
      "                                 (None, 256),                     'encoder_lstm[0][1]',           \n",
      "                                 (None, 256)]                     'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " decoder_out (Dense)            (None, None, 87)     22359       ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 741,207\n",
      "Trainable params: 741,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create maps to convert characters to and from ints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_token2int = {token : i for i, token in enumerate(sorted(in_vocab))}\n",
    "out_token2int = {token : i for i, token in enumerate(sorted(out_vocab))}\n",
    "out_int2token = {i : token for (token, i) in out_token2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"esCharToInt.json\", \"w\") as f:\n",
    "    json.dump(in_token2int, f)\n",
    "with open(\"intToEnChar.json\", \"w\") as f:\n",
    "    json.dump(out_int2token, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions for one-hot encoding sequences for use with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_batch_storage(batch_size, in_seq_len, out_seq_len):\n",
    "    \n",
    "    enc_in_seqs = np.zeros(\n",
    "        (batch_size, in_seq_len, in_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_in_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_out_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "        \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(samples):\n",
    "    batch_size = len(samples)\n",
    "    max_in_length = max([len(seq) for seq, _ in samples])\n",
    "    max_out_length = max([len(seq) for _, seq in samples])\n",
    "\n",
    "    enc_in_seqs, dec_in_seqs, dec_out_seqs = make_batch_storage(\n",
    "        batch_size, max_in_length, max_out_length)\n",
    "    \n",
    "    for i, (in_seq, out_seq) in enumerate(samples):\n",
    "        for time_step, token in enumerate(in_seq):\n",
    "            enc_in_seqs[i, time_step, in_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq):\n",
    "            dec_in_seqs[i, time_step, out_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq[1:]):\n",
    "            dec_out_seqs[i, time_step, out_token2int[token]] = 1\n",
    "            \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_util import Seq2SeqBatchGenerator\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = Seq2SeqBatchGenerator(train_samples, batch_size, encode_batch)\n",
    "valid_generator = Seq2SeqBatchGenerator(valid_samples, batch_size, encode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-57ff8f760a77>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  seq2seq_model.fit_generator(train_generator, epochs=500,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1247/1247 [==============================] - 420s 333ms/step - loss: 1.4484 - val_loss: 1.1514\n",
      "Epoch 2/500\n",
      "1247/1247 [==============================] - 417s 335ms/step - loss: 1.1478 - val_loss: 0.9840\n",
      "Epoch 3/500\n",
      "1247/1247 [==============================] - 409s 328ms/step - loss: 1.0373 - val_loss: 0.9091\n",
      "Epoch 4/500\n",
      "1247/1247 [==============================] - 407s 326ms/step - loss: 0.9852 - val_loss: 0.8948\n",
      "Epoch 5/500\n",
      "1247/1247 [==============================] - 413s 331ms/step - loss: 0.9515 - val_loss: 0.8372\n",
      "Epoch 6/500\n",
      "1247/1247 [==============================] - 408s 327ms/step - loss: 0.9288 - val_loss: 0.8081\n",
      "Epoch 7/500\n",
      "1247/1247 [==============================] - 407s 326ms/step - loss: 0.9114 - val_loss: 0.7972\n",
      "Epoch 8/500\n",
      "1247/1247 [==============================] - 408s 327ms/step - loss: 0.9007 - val_loss: 0.7865\n",
      "Epoch 9/500\n",
      "1247/1247 [==============================] - 408s 327ms/step - loss: 0.8926 - val_loss: 0.7737\n",
      "Epoch 10/500\n",
      "1247/1247 [==============================] - 398s 319ms/step - loss: 0.8848 - val_loss: 0.7652\n",
      "Epoch 11/500\n",
      "1247/1247 [==============================] - 399s 320ms/step - loss: 0.8798 - val_loss: 0.7608\n",
      "Epoch 12/500\n",
      "1247/1247 [==============================] - 391s 314ms/step - loss: 0.8737 - val_loss: 0.7431\n",
      "Epoch 13/500\n",
      "1247/1247 [==============================] - 386s 310ms/step - loss: 0.8687 - val_loss: 0.7493\n",
      "Epoch 14/500\n",
      "1247/1247 [==============================] - 388s 311ms/step - loss: 0.8660 - val_loss: 0.7318\n",
      "Epoch 15/500\n",
      "1247/1247 [==============================] - 389s 312ms/step - loss: 0.8628 - val_loss: 0.7431\n",
      "Epoch 16/500\n",
      "1247/1247 [==============================] - 390s 313ms/step - loss: 0.8613 - val_loss: 0.7299\n",
      "Epoch 17/500\n",
      "1247/1247 [==============================] - 389s 312ms/step - loss: 0.8567 - val_loss: 0.7265\n",
      "Epoch 18/500\n",
      "1247/1247 [==============================] - 383s 307ms/step - loss: 0.8588 - val_loss: 0.7248\n",
      "Epoch 19/500\n",
      "1247/1247 [==============================] - 388s 311ms/step - loss: 0.8562 - val_loss: 0.7343\n",
      "Epoch 20/500\n",
      "1247/1247 [==============================] - 389s 312ms/step - loss: 0.8570 - val_loss: 0.7473\n",
      "Epoch 21/500\n",
      "1247/1247 [==============================] - 387s 310ms/step - loss: 0.8547 - val_loss: 0.7167\n",
      "Epoch 22/500\n",
      "1247/1247 [==============================] - 382s 307ms/step - loss: 0.8557 - val_loss: 0.7282\n",
      "Epoch 23/500\n",
      "1247/1247 [==============================] - 389s 312ms/step - loss: 0.8563 - val_loss: 0.7292\n",
      "Epoch 24/500\n",
      "1247/1247 [==============================] - 383s 307ms/step - loss: 0.8566 - val_loss: 0.7429\n",
      "Epoch 25/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8563 - val_loss: 0.7143\n",
      "Epoch 26/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8575 - val_loss: 0.7204\n",
      "Epoch 27/500\n",
      "1247/1247 [==============================] - 379s 304ms/step - loss: 0.8593 - val_loss: 0.7112\n",
      "Epoch 28/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8604 - val_loss: 0.7114\n",
      "Epoch 29/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8619 - val_loss: 0.7215\n",
      "Epoch 30/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8616 - val_loss: 0.7181\n",
      "Epoch 31/500\n",
      "1247/1247 [==============================] - 380s 304ms/step - loss: 0.8632 - val_loss: 0.7105\n",
      "Epoch 32/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8643 - val_loss: 0.7061\n",
      "Epoch 33/500\n",
      "1247/1247 [==============================] - 381s 305ms/step - loss: 0.8670 - val_loss: 0.7179\n",
      "Epoch 34/500\n",
      "1247/1247 [==============================] - 380s 305ms/step - loss: 0.8706 - val_loss: 0.7256\n",
      "Epoch 35/500\n",
      "1247/1247 [==============================] - 382s 306ms/step - loss: 0.8758 - val_loss: 0.7445\n",
      "Epoch 36/500\n",
      "1247/1247 [==============================] - 381s 305ms/step - loss: 0.8728 - val_loss: 0.7164\n",
      "Epoch 37/500\n",
      "1247/1247 [==============================] - 381s 305ms/step - loss: 0.8752 - val_loss: 0.7231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffe8c4abe50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "seq2seq_model.fit_generator(train_generator, epochs=500,\n",
    "                            validation_data=valid_generator,\n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoder/decoder models for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder = Model(encoder_in, [encoder_h, encoder_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_in (InputLayer)     [(None, None, 101)]       0         \n",
      "                                                                 \n",
      " encoder_mask (Masking)      (None, None, 101)         0         \n",
      "                                                                 \n",
      " encoder_lstm (LSTM)         [(None, 256),             366592    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366,592\n",
      "Trainable params: 366,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dec_h_in = Input(shape=(latent_dim,), name=\"decoder_h_in\")\n",
    "inf_dec_c_in = Input(shape=(latent_dim,), name=\"decoder_c_in\")\n",
    "\n",
    "inf_dec_lstm_out, inf_dec_h_out, inf_dec_c_out = decoder_lstm(\n",
    "    decoder_in, initial_state=[inf_dec_h_in, inf_dec_c_in])\n",
    "\n",
    "inf_dec_out = decoder_dense(inf_dec_lstm_out)\n",
    "\n",
    "inf_decoder = Model(\n",
    "    [decoder_in, inf_dec_h_in, inf_dec_c_in],\n",
    "    [inf_dec_out, inf_dec_h_out, inf_dec_c_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_in (InputLayer)        [(None, None, 87)]   0           []                               \n",
      "                                                                                                  \n",
      " decoder_h_in (InputLayer)      [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_c_in (InputLayer)      [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 256),  352256      ['decoder_in[0][0]',             \n",
      "                                 (None, 256),                     'decoder_h_in[0][0]',           \n",
      "                                 (None, 256)]                     'decoder_c_in[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_out (Dense)            (None, None, 87)     22359       ['decoder_lstm[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 374,615\n",
      "Trainable params: 374,615\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test trained model on the first 100 samples from both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max output length:  87\n"
     ]
    }
   ],
   "source": [
    "max_out_seq_len = max([len(seq) for _, seq in samples])\n",
    "print(\"Max output length: \", max_out_seq_len)\n",
    "\n",
    "start_token_idx = out_token2int[start_token]\n",
    "stop_token_idx = out_token2int[stop_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(one_hot_seq, encoder, decoder):\n",
    "    encoding = encoder.predict(one_hot_seq)\n",
    "\n",
    "    decoder_in = np.zeros((1, 1, out_vocab_size), dtype=np.float32)\n",
    "\n",
    "    translated_text = ''\n",
    "    done_decoding = False\n",
    "    decoded_idx = start_token_idx\n",
    "    while not done_decoding:\n",
    "        decoder_in[0, 0, decoded_idx] = 1\n",
    "        decoding, h, c = decoder.predict([decoder_in] + encoding)\n",
    "        encoding = [h, c]\n",
    "        decoder_in[0, 0, decoded_idx] = 0\n",
    "\n",
    "        decoded_idx = np.argmax(decoding[0, -1, :])\n",
    "        \n",
    "        if decoded_idx == stop_token_idx:\n",
    "            done_decoding = True\n",
    "        else:\n",
    "            translated_text += out_int2token[decoded_idx]\n",
    "\n",
    "        if len(translated_text) >= max_out_seq_len:\n",
    "            done_decoding = True\n",
    "            \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: A todos nos gusta montar en bici.\n",
      "Dataset translation: \tWe all like cycling.\n",
      "\n",
      "Model output: All the some are something.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se rió de todos los chistes de Mary.\n",
      "Dataset translation: \tTom laughed at all of Mary's jokes.\n",
      "\n",
      "Model output: Tom stopped Mary a little the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom es un asqueroso.\n",
      "Dataset translation: \tTom is a creep.\n",
      "\n",
      "Model output: Tom is a good the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu meta en la vida?\n",
      "Dataset translation: \tWhat's your aim in life?\n",
      "\n",
      "Model output: What's your favorite the back?\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le escucha, aunque nadie más lo haga.\n",
      "Dataset translation: \tShe listens to him even though no one else does.\n",
      "\n",
      "Model output: She is almost the start the book to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Ganar o perder no es la cuestión.\n",
      "Dataset translation: \tIt doesn't matter whether you win or not.\n",
      "\n",
      "Model output: It was too the book and the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Es un privilegio conocerte.\n",
      "Dataset translation: \tIt is a privilege to meet you.\n",
      "\n",
      "Model output: It's a strange the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Disculpe, se me han caído los palillos.\n",
      "Dataset translation: \tExcuse me, I dropped a chopstick.\n",
      "\n",
      "Model output: Excuse the start, I was to stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un jardín delante de nuestra casa.\n",
      "Dataset translation: \tThere's a garden in front of our house.\n",
      "\n",
      "Model output: There is a big for a little the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Corrí alrededor del campo.\n",
      "Dataset translation: \tI ran around the field.\n",
      "\n",
      "Model output: I read the book to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Nunca me he olvidado de ustedes.\n",
      "Dataset translation: \tI've never forgotten you.\n",
      "\n",
      "Model output: I've never seen the parting to do.\n",
      "-----------------------------------------\n",
      "Input sentence: A él le operaron la pierna izquierda.\n",
      "Dataset translation: \tHe had an operation on his left leg.\n",
      "\n",
      "Model output: He was almost to be a lot the back.\n",
      "-----------------------------------------\n",
      "Input sentence: He hecho cosas cuestionables.\n",
      "Dataset translation: \tI've done questionable things.\n",
      "\n",
      "Model output: I've been a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy estudiante de la universidad Hyogo.\n",
      "Dataset translation: \tI am a student at Hyogo University.\n",
      "\n",
      "Model output: I'm a little to speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo la impresión de que ella vendrá hoy.\n",
      "Dataset translation: \tI have an idea she will come today.\n",
      "\n",
      "Model output: I have to see the story and stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Está estudiando chino.\n",
      "Dataset translation: \tHe's studying Chinese.\n",
      "\n",
      "Model output: It's almost to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que va a llover hoy.\n",
      "Dataset translation: \tI think it's going to rain today.\n",
      "\n",
      "Model output: I think that he was to school.\n",
      "-----------------------------------------\n",
      "Input sentence: Un niño conducía un rebaño de ovejas.\n",
      "Dataset translation: \tA boy was driving a flock of sheep.\n",
      "\n",
      "Model output: A book is a lot of the book to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy escribiendo una carta.\n",
      "Dataset translation: \tI'm writing a letter.\n",
      "\n",
      "Model output: I'm sure to stay to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Te llevaré a nadar.\n",
      "Dataset translation: \tI will take you for a swim.\n",
      "\n",
      "Model output: I'll tell you the book.\n",
      "-----------------------------------------\n",
      "Input sentence: No falta nada.\n",
      "Dataset translation: \tNothing is missing.\n",
      "\n",
      "Model output: Don't be a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo le indiqué el camino.\n",
      "Dataset translation: \tI showed him the way.\n",
      "\n",
      "Model output: I advised him to do the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué quieres decir?\n",
      "Dataset translation: \tWhatever do you mean?\n",
      "\n",
      "Model output: What do you want to do?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom necesita un cambio de decorado.\n",
      "Dataset translation: \tTom needs a change of scenery.\n",
      "\n",
      "Model output: Tom needs a studing the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Pártelo a la mitad.\n",
      "Dataset translation: \tCut it in half.\n",
      "\n",
      "Model output: Say the book.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Ya decidiste qué hacer?\n",
      "Dataset translation: \tHave you decided what to do yet?\n",
      "\n",
      "Model output: Did you see that he was the back?\n",
      "-----------------------------------------\n",
      "Input sentence: El entusiasmo es contagioso.\n",
      "Dataset translation: \tEnthusiasm is contagious.\n",
      "\n",
      "Model output: The stranger is a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Tanto Tom como Mary estudian francés.\n",
      "Dataset translation: \tTom and Mary both study French.\n",
      "\n",
      "Model output: Tom Tom Mary was a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Me gusta oír buena música.\n",
      "Dataset translation: \tI like listening to good music.\n",
      "\n",
      "Model output: I like to speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: Muchísimas gracias por el regalo.\n",
      "Dataset translation: \tThank you very much for your gift.\n",
      "\n",
      "Model output: Thank you for the book to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tú estás interfiriendo.\n",
      "Dataset translation: \tYou're interfering.\n",
      "\n",
      "Model output: You're always anything.\n",
      "-----------------------------------------\n",
      "Input sentence: Acabo de verlo.\n",
      "Dataset translation: \tI saw him just now.\n",
      "\n",
      "Model output: I just be a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Déjame pensar esto de nuevo.\n",
      "Dataset translation: \tLet me think this over.\n",
      "\n",
      "Model output: Let me see the stary the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero creer que es así.\n",
      "Dataset translation: \tI'd like to think so.\n",
      "\n",
      "Model output: I want to stay that the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Hagamos lo que dijo Tom.\n",
      "Dataset translation: \tLet's do what Tom said.\n",
      "\n",
      "Model output: Let's get that Tom was the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom una vez trabajó en una panadería.\n",
      "Dataset translation: \tTom once worked at a bakery.\n",
      "\n",
      "Model output: Tom has a lot of the book to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: A ellos les gusta jugar juntos.\n",
      "Dataset translation: \tThey enjoy playing together.\n",
      "\n",
      "Model output: You like to speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres ir primero?\n",
      "Dataset translation: \tDo you want to go first?\n",
      "\n",
      "Model output: Do you want to stay the train?\n",
      "-----------------------------------------\n",
      "Input sentence: Esperamos visitar España este verano.\n",
      "Dataset translation: \tWe are hoping to visit Spain this summer.\n",
      "\n",
      "Model output: We had a lot of the book with him.\n",
      "-----------------------------------------\n",
      "Input sentence: No entiendo lo que quiere decir.\n",
      "Dataset translation: \tI don't understand what you mean.\n",
      "\n",
      "Model output: I don't feel like to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando el agua se congela se vuelve hielo.\n",
      "Dataset translation: \tWhen water freezes it becomes ice.\n",
      "\n",
      "Model output: When the start is the start of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Alguna vez has comido insectos?\n",
      "Dataset translation: \tHave you ever eaten insects?\n",
      "\n",
      "Model output: Have you ever seen a lot?\n",
      "-----------------------------------------\n",
      "Input sentence: Sal del agua.\n",
      "Dataset translation: \tGet out of the water.\n",
      "\n",
      "Model output: Get the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Él se quedó en mi hogar por tres semanas.\n",
      "Dataset translation: \tHe stayed at my place for three weeks.\n",
      "\n",
      "Model output: He had a lot of the book to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom hace su mejor esfuerzo.\n",
      "Dataset translation: \tTom is doing his best.\n",
      "\n",
      "Model output: Tom has a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo estuvo de acuerdo.\n",
      "Dataset translation: \tEverybody was in agreement.\n",
      "\n",
      "Model output: Everybody has a studing.\n",
      "-----------------------------------------\n",
      "Input sentence: Si quieres tu dinero de vuelta, solo dilo.\n",
      "Dataset translation: \tIf you want your money back, just say so.\n",
      "\n",
      "Model output: If you want to see you, I was to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Nadie me dijo nada.\n",
      "Dataset translation: \tNo one said anything to me.\n",
      "\n",
      "Model output: Nobody knows him.\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom le gusta estar rodeado de gente.\n",
      "Dataset translation: \tTom likes having people around.\n",
      "\n",
      "Model output: Tom likes to speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: Tu madre se encuentra en estado crítico.\n",
      "Dataset translation: \tYour mother is in critical condition.\n",
      "\n",
      "Model output: Your father is a little to stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un gato debajo de la mesa.\n",
      "Dataset translation: \tThere's a cat under the table.\n",
      "\n",
      "Model output: There's a beauting to see the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Esto no es un sueño.\n",
      "Dataset translation: \tIt isn't a dream.\n",
      "\n",
      "Model output: This is not a studer.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos son vuestros.\n",
      "Dataset translation: \tThey're yours.\n",
      "\n",
      "Model output: They're all the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Mañana, él alunizará.\n",
      "Dataset translation: \tTomorrow he lands on the moon.\n",
      "\n",
      "Model output: I will be a lot of the money.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jugaré contigo.\n",
      "Dataset translation: \tI'll play with you.\n",
      "\n",
      "Model output: I'll be a lot the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom está gordo.\n",
      "Dataset translation: \tTom is fat.\n",
      "\n",
      "Model output: Tom's stop.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedo reservar un vuelo a Chicago?\n",
      "Dataset translation: \tCan I reserve a flight to Chicago?\n",
      "\n",
      "Model output: Can I see you a lot of the back?\n",
      "-----------------------------------------\n",
      "Input sentence: Él asistió a muchas ceremonias.\n",
      "Dataset translation: \tHe attended many ceremonies.\n",
      "\n",
      "Model output: He almost too much the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Nos sentamos ahí.\n",
      "Dataset translation: \tWe sat there.\n",
      "\n",
      "Model output: We are all the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Es todo.\n",
      "Dataset translation: \tThat is all.\n",
      "\n",
      "Model output: It's reading.\n",
      "-----------------------------------------\n",
      "Input sentence: Su vida está llena de problemas.\n",
      "Dataset translation: \tHis life is full of trouble.\n",
      "\n",
      "Model output: His right is to stay the bad.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué estás esperando?\n",
      "Dataset translation: \tWhat are you waiting for?\n",
      "\n",
      "Model output: What are you so the train?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo puedes aguantarlo?\n",
      "Dataset translation: \tHow can you stand it?\n",
      "\n",
      "Model output: How can you speak the train?\n",
      "-----------------------------------------\n",
      "Input sentence: María perdió sus lentes de lectura.\n",
      "Dataset translation: \tMary lost her reading glasses.\n",
      "\n",
      "Model output: Mary has a stranged to stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ahora lo digo de veras.\n",
      "Dataset translation: \tI mean it this time.\n",
      "\n",
      "Model output: I don't like the book.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos eran hombres conservadores.\n",
      "Dataset translation: \tThey were conservative men.\n",
      "\n",
      "Model output: They were been to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Quisiera una taza de té.\n",
      "Dataset translation: \tI'd like a cup of tea.\n",
      "\n",
      "Model output: I'd like to speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intenta esconder?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What does the stary?\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom no le gustó Mary.\n",
      "Dataset translation: \tTom didn't like Mary.\n",
      "\n",
      "Model output: Tom didn't like Mary.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intentáis ocultar?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What do you speak French?\n",
      "-----------------------------------------\n",
      "Input sentence: La táctica funcionó.\n",
      "Dataset translation: \tThe tactic worked.\n",
      "\n",
      "Model output: The car is a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Vine por ustedes.\n",
      "Dataset translation: \tI came for you.\n",
      "\n",
      "Model output: I came to stop.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Te debo algo?\n",
      "Dataset translation: \tDo I owe you something?\n",
      "\n",
      "Model output: What do I go the train?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me ayudas a mover la mesa?\n",
      "Dataset translation: \tCan you help me move the table?\n",
      "\n",
      "Model output: Can you see me to see the back?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom arriesgó su vida para salvar a Mary.\n",
      "Dataset translation: \tTom risked his life to save Mary.\n",
      "\n",
      "Model output: Tom read to speak French to the book.\n",
      "-----------------------------------------\n",
      "Input sentence: He comprado aquí durante siglos.\n",
      "Dataset translation: \tI've shopped here for ages.\n",
      "\n",
      "Model output: I have a stranged to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Até a mi perro a un árbol del jardín.\n",
      "Dataset translation: \tI tied my dog to a tree in the garden.\n",
      "\n",
      "Model output: I have a lot of the book and stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy de Kioto.\n",
      "Dataset translation: \tI'm from Kyoto.\n",
      "\n",
      "Model output: I'm very car.\n",
      "-----------------------------------------\n",
      "Input sentence: Las niñas no jugarán al tenis mañana.\n",
      "Dataset translation: \tThe girls will not play tennis tomorrow.\n",
      "\n",
      "Model output: The parents are something to speak the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Todas las mañanas voy de compras.\n",
      "Dataset translation: \tI go shopping every morning.\n",
      "\n",
      "Model output: All the some are something to do the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que plantar árboles en el jardín.\n",
      "Dataset translation: \tI have to plant trees in the garden.\n",
      "\n",
      "Model output: I have to speak a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para servir o para llevar?\n",
      "Dataset translation: \tFor here, or to go?\n",
      "\n",
      "Model output: Would you go to the part the back?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo supiste que iba a pasar eso?\n",
      "Dataset translation: \tHow did you know that was going to happen?\n",
      "\n",
      "Model output: How did you know that he was to see the train?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió en un accidente de tráfico.\n",
      "Dataset translation: \tTom died in a traffic accident.\n",
      "\n",
      "Model output: Tom died a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ya no estoy casada con Tom.\n",
      "Dataset translation: \tI'm no longer married to Tom.\n",
      "\n",
      "Model output: I'm not all so that Tom.\n",
      "-----------------------------------------\n",
      "Input sentence: No es un reloj.\n",
      "Dataset translation: \tIt is not a watch.\n",
      "\n",
      "Model output: It's not a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Te ayudaré si es posible.\n",
      "Dataset translation: \tI will help you if possible.\n",
      "\n",
      "Model output: I'll see you to see you the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella realmente quería decir el secreto.\n",
      "Dataset translation: \tShe really wanted to tell the secret.\n",
      "\n",
      "Model output: She really was to stay that the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella se tiñó de rubio.\n",
      "Dataset translation: \tShe dyed her hair blonde.\n",
      "\n",
      "Model output: She took him a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has necesitado ayuda alguna vez?\n",
      "Dataset translation: \tHave you ever needed help?\n",
      "\n",
      "Model output: Have you ever seen the parting?\n",
      "-----------------------------------------\n",
      "Input sentence: He venido a despedirme.\n",
      "Dataset translation: \tI've come to say goodbye.\n",
      "\n",
      "Model output: I've been too much the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Sé que no es una broma.\n",
      "Dataset translation: \tI know it's not a joke.\n",
      "\n",
      "Model output: I know you want to stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo cocinaré.\n",
      "Dataset translation: \tI'll cook.\n",
      "\n",
      "Model output: I will be the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Fuera de mi propiedad.\n",
      "Dataset translation: \tGet off my property.\n",
      "\n",
      "Model output: She was able to stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedes venir un momento?\n",
      "Dataset translation: \tWould you come here a moment?\n",
      "\n",
      "Model output: Can you see a lot of the train?\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se ve aburrido.\n",
      "Dataset translation: \tTom looks bored.\n",
      "\n",
      "Model output: Tom looks a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Mira! Hay un avión despegando.\n",
      "Dataset translation: \tLook! There's a plane taking off.\n",
      "\n",
      "Model output: Look an a lot of the start to Tom.\n",
      "-----------------------------------------\n",
      "Input sentence: Este libro no es mío.\n",
      "Dataset translation: \tThis book isn't mine.\n",
      "\n",
      "Model output: This book is not the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom bebe.\n",
      "Dataset translation: \tTom drinks.\n",
      "\n",
      "Model output: Tom know.\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando lo oyó, le entraron ganas de llorar.\n",
      "Dataset translation: \tWhen she heard that, she felt like crying.\n",
      "\n",
      "Model output: When I did the start of the start to the back.\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_util import test_predictions\n",
    "\n",
    "test_predictions(valid_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Después de una larga espera pudimos entrar.\n",
      "Dataset translation: \tWe got in after a long wait.\n",
      "\n",
      "Model output: An the start is a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo siento, pero es imposible.\n",
      "Dataset translation: \tI'm sorry, but it's impossible.\n",
      "\n",
      "Model output: I'm sorry, I was to stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Parecía satisfecho.\n",
      "Dataset translation: \tHe looked pleased.\n",
      "\n",
      "Model output: It seems to stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Saqué el pastel del horno.\n",
      "Dataset translation: \tI took the cake out of the oven.\n",
      "\n",
      "Model output: I was a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Es un trabajo muy difícil.\n",
      "Dataset translation: \tThat's a very tough job.\n",
      "\n",
      "Model output: It's a stranger to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Dijiste que no entendías.\n",
      "Dataset translation: \tYou said you didn't understand.\n",
      "\n",
      "Model output: You said you want to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo te está esperando.\n",
      "Dataset translation: \tEverybody is waiting for you.\n",
      "\n",
      "Model output: Everybody is a littled.\n",
      "-----------------------------------------\n",
      "Input sentence: Recuerdo lo que era.\n",
      "Dataset translation: \tI remember what it was.\n",
      "\n",
      "Model output: I remember that he do.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom aterrizó su helicóptero sobre el techo.\n",
      "Dataset translation: \tTom landed his helicopter on the roof.\n",
      "\n",
      "Model output: Tom read the stort to be a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom pidió direcciones.\n",
      "Dataset translation: \tTom asked for directions.\n",
      "\n",
      "Model output: Tom asked his car.\n",
      "-----------------------------------------\n",
      "Input sentence: Él tiene una personalidad dócil.\n",
      "Dataset translation: \tHe has a mild nature.\n",
      "\n",
      "Model output: He has a book a lot the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Hago ejercicios dos horas por día.\n",
      "Dataset translation: \tI exercise for two hours every day.\n",
      "\n",
      "Model output: I was a lot of the book to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: No me creerán aunque les jure que es cierto.\n",
      "Dataset translation: \tThey won't believe me even if I swear it is true.\n",
      "\n",
      "Model output: They don't want to see you to see the back.\n",
      "-----------------------------------------\n",
      "Input sentence: He dado el primer paso.\n",
      "Dataset translation: \tI've taken the first step.\n",
      "\n",
      "Model output: I've been the book to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom y yo trabajamos juntos.\n",
      "Dataset translation: \tTom and I work together.\n",
      "\n",
      "Model output: Tom and I have a strange the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Él es mucho mejor que tú.\n",
      "Dataset translation: \tHe is much better than you.\n",
      "\n",
      "Model output: He is very starting the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ven cualquier día que quieras.\n",
      "Dataset translation: \tCome on any day you like.\n",
      "\n",
      "Model output: Come of the weat we have the back.\n",
      "-----------------------------------------\n",
      "Input sentence: El gerente dijo que era culpa tuya.\n",
      "Dataset translation: \tThe manager said it was your fault.\n",
      "\n",
      "Model output: The strain is to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió feliz.\n",
      "Dataset translation: \tTom died happy.\n",
      "\n",
      "Model output: Tom died the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Le vi nuevamente.\n",
      "Dataset translation: \tI saw him again.\n",
      "\n",
      "Model output: I saw him to stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella dejó a los niños al cuidado de su tía.\n",
      "Dataset translation: \tShe left her children in her aunt's care.\n",
      "\n",
      "Model output: She left the start of the book to do the back.\n",
      "-----------------------------------------\n",
      "Input sentence: El arte no es un lujo, sino una necesidad.\n",
      "Dataset translation: \tArt is not a luxury, but a necessity.\n",
      "\n",
      "Model output: The stor is no eating to see the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Había todo tipo de actividades grupales.\n",
      "Dataset translation: \tThere were all sorts of group activities.\n",
      "\n",
      "Model output: There were a lot of the book at the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Él te aconsejará al respecto.\n",
      "Dataset translation: \tHe will advise you on that matter.\n",
      "\n",
      "Model output: He will be a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tú no eres japonés.\n",
      "Dataset translation: \tYou are not Japanese.\n",
      "\n",
      "Model output: You're not a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que cocinar la cena hoy.\n",
      "Dataset translation: \tI have to cook dinner today.\n",
      "\n",
      "Model output: I have to stay the book.\n",
      "-----------------------------------------\n",
      "Input sentence: Soy mejor.\n",
      "Dataset translation: \tI am better.\n",
      "\n",
      "Model output: I'm very the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Te queda bien.\n",
      "Dataset translation: \tThat looks good on you.\n",
      "\n",
      "Model output: You look the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Cenaremos juntos y luego iremos al teatro.\n",
      "Dataset translation: \tWe'll dine together and then go to the theater.\n",
      "\n",
      "Model output: We spend the start and start to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Pasemos adentro.\n",
      "Dataset translation: \tLet's step inside.\n",
      "\n",
      "Model output: Let's speak a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: No me puedo costear un auto nuevo.\n",
      "Dataset translation: \tI can't afford a new car.\n",
      "\n",
      "Model output: I can't stay a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: «¿A qué hora os levantáis?»«A las ocho.»\n",
      "Dataset translation: \t\"What time do you guys wake up?\" \"Eight o'clock.\"\n",
      "\n",
      "Model output: What time do you speak Boston the book?\n",
      "-----------------------------------------\n",
      "Input sentence: Es un error decir mentiras.\n",
      "Dataset translation: \tIt is wrong to tell a lie.\n",
      "\n",
      "Model output: It's a strang the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos me mostraron muchas fotos hermosas.\n",
      "Dataset translation: \tThey showed me a lot of beautiful photos.\n",
      "\n",
      "Model output: They showed me a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Ojalá pudiera bailar todos los días.\n",
      "Dataset translation: \tI wish I could dance every day.\n",
      "\n",
      "Model output: I wish I was a lot of the book.\n",
      "-----------------------------------------\n",
      "Input sentence: Intenté escribir con la mano izquierda.\n",
      "Dataset translation: \tI tried writing with my left hand.\n",
      "\n",
      "Model output: I tried to stay a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jamás te traicionaría.\n",
      "Dataset translation: \tI'd never betray you.\n",
      "\n",
      "Model output: I will never see a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Tomás canta bastante bien.\n",
      "Dataset translation: \tTom sings quite well.\n",
      "\n",
      "Model output: Tom can speak French.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo sé conducir un coche, pero Tom no.\n",
      "Dataset translation: \tI can drive a car, but Tom can't.\n",
      "\n",
      "Model output: I know where I was too my family.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se portó, para ser un principiante.\n",
      "Dataset translation: \tTom did well for a beginner.\n",
      "\n",
      "Model output: Tom spent the start of the bad the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo traeré de vuelta.\n",
      "Dataset translation: \tI'll bring it back.\n",
      "\n",
      "Model output: I'll be better the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Casi tengo treinta años.\n",
      "Dataset translation: \tI'm almost thirty.\n",
      "\n",
      "Model output: I am sorry to stop the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom observa a Mary.\n",
      "Dataset translation: \tTom watches Mary.\n",
      "\n",
      "Model output: Tom spend Mary.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres verlo?\n",
      "Dataset translation: \tDo you want to see it?\n",
      "\n",
      "Model output: Do you want to do?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué tiene ella?\n",
      "Dataset translation: \tWhat does she have?\n",
      "\n",
      "Model output: What does the part?\n",
      "-----------------------------------------\n",
      "Input sentence: La mayoría de la gente no lo haría así.\n",
      "Dataset translation: \tMost people wouldn't do that that way.\n",
      "\n",
      "Model output: The some is a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Leí el libro entero.\n",
      "Dataset translation: \tI read the entire book.\n",
      "\n",
      "Model output: I read the story something.\n",
      "-----------------------------------------\n",
      "Input sentence: Tienes que responder a la pregunta.\n",
      "Dataset translation: \tYou need to answer the question.\n",
      "\n",
      "Model output: You must be a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has vivido aquí?\n",
      "Dataset translation: \tDid you live here?\n",
      "\n",
      "Model output: Have you ever got the train?\n",
      "-----------------------------------------\n",
      "Input sentence: He decidido hacer eso solo.\n",
      "Dataset translation: \tI've decided to do that by myself.\n",
      "\n",
      "Model output: I've decided to stay a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le vio comerse un sándwich.\n",
      "Dataset translation: \tShe saw him eating a sandwich.\n",
      "\n",
      "Model output: She saw him a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: No quiero esta camisa.\n",
      "Dataset translation: \tI don't want this shirt.\n",
      "\n",
      "Model output: I don't want to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Él se marchó hace diez minutos.\n",
      "Dataset translation: \tHe left ten minutes ago.\n",
      "\n",
      "Model output: He did a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Sabes por qué Tom vino aquí hoy?\n",
      "Dataset translation: \tDo you know the reason Tom came here today?\n",
      "\n",
      "Model output: Do you know what I want to see Tom?\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me podrías pasar la sal, por favor?\n",
      "Dataset translation: \tCould you pass me the salt, please?\n",
      "\n",
      "Model output: Could you speak the story and the bad?\n",
      "-----------------------------------------\n",
      "Input sentence: No le gustan las cosas dulces.\n",
      "Dataset translation: \tHe doesn't care for sweet things.\n",
      "\n",
      "Model output: He doesn't like to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Hoy es jueves.\n",
      "Dataset translation: \tToday is Thursday.\n",
      "\n",
      "Model output: Today is a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom no se ha sentido muy bien recientemente.\n",
      "Dataset translation: \tTom hasn't been very well recently.\n",
      "\n",
      "Model output: Tom hasn't seen the book a lot the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Todo lo que sé es que él viene de China.\n",
      "Dataset translation: \tAll I know is that he came from China.\n",
      "\n",
      "Model output: Everything is that that he's no beauth.\n",
      "-----------------------------------------\n",
      "Input sentence: Dígame cuando desee hacer su orden.\n",
      "Dataset translation: \tTell me when you'd like to order.\n",
      "\n",
      "Model output: Tell me what you want to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Qué perro más grande!\n",
      "Dataset translation: \tWhat a huge dog!\n",
      "\n",
      "Model output: What a studing the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Conseguimos llegar allá a tiempo.\n",
      "Dataset translation: \tWe managed to get there on time.\n",
      "\n",
      "Model output: We started the start of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Vete ya!\n",
      "Dataset translation: \tGo away.\n",
      "\n",
      "Model output: Go the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Él me envió una tarjeta de cumpleaños.\n",
      "Dataset translation: \tHe sent me a birthday card.\n",
      "\n",
      "Model output: He felt a lot of the parting to do.\n",
      "-----------------------------------------\n",
      "Input sentence: No te recuerdo.\n",
      "Dataset translation: \tI don't remember you.\n",
      "\n",
      "Model output: I didn't see the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero hacerlo tan a menudo como pueda.\n",
      "Dataset translation: \tI want to do that as often as I can.\n",
      "\n",
      "Model output: I want to speak a lot of the book.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para qué se está escondiendo Tom?\n",
      "Dataset translation: \tWhat's Tom hiding for?\n",
      "\n",
      "Model output: What's Tom want to do?\n",
      "-----------------------------------------\n",
      "Input sentence: Me da una enchinada.\n",
      "Dataset translation: \tIt creeps me out.\n",
      "\n",
      "Model output: I have a studing.\n",
      "-----------------------------------------\n",
      "Input sentence: Tom nunca lastimaría a sus hijos.\n",
      "Dataset translation: \tTom would never hurt his children.\n",
      "\n",
      "Model output: Tom will never see the parting to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Consiguió que la máquina funcionara.\n",
      "Dataset translation: \tHe managed to run the machine.\n",
      "\n",
      "Model output: He can asked that he was a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Bienvenido a tu nuevo hogar!\n",
      "Dataset translation: \tWelcome to your new home.\n",
      "\n",
      "Model output: Welcome the something.\n",
      "-----------------------------------------\n",
      "Input sentence: Yo hice esta silla.\n",
      "Dataset translation: \tI made this chair.\n",
      "\n",
      "Model output: I did that the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Te traje café.\n",
      "Dataset translation: \tI brought you some coffee.\n",
      "\n",
      "Model output: I try to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Má, ¡apúrate! Están todos esperando.\n",
      "Dataset translation: \tMom, hurry up! Everyone's waiting.\n",
      "\n",
      "Model output: Tom, I was something to see you the back.\n",
      "-----------------------------------------\n",
      "Input sentence: El viernes es cuando estoy menos ocupado.\n",
      "Dataset translation: \tFriday is when I am least busy.\n",
      "\n",
      "Model output: The stort is a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que el tren vendrá pronto.\n",
      "Dataset translation: \tI think the train will come soon.\n",
      "\n",
      "Model output: I think you're still the book.\n",
      "-----------------------------------------\n",
      "Input sentence: El sombrero estaba sucio por arriba.\n",
      "Dataset translation: \tThe hat was dirty around the top.\n",
      "\n",
      "Model output: The rain is a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Por favor, hable más rápido.\n",
      "Dataset translation: \tPlease speak more quickly.\n",
      "\n",
      "Model output: Please speak me a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: El despertador sonó.\n",
      "Dataset translation: \tThe alarm went off.\n",
      "\n",
      "Model output: The problem is stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Los ricos tienen muchos amigos.\n",
      "Dataset translation: \tThe rich have many friends.\n",
      "\n",
      "Model output: The strands are something the back.\n",
      "-----------------------------------------\n",
      "Input sentence: No confíe en él.\n",
      "Dataset translation: \tDon't trust him.\n",
      "\n",
      "Model output: Don't trust the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Habló del accidente?\n",
      "Dataset translation: \tDid he mention the accident?\n",
      "\n",
      "Model output: Did you speak French?\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy desempleada.\n",
      "Dataset translation: \tI'm unemployed.\n",
      "\n",
      "Model output: I'm staying.\n",
      "-----------------------------------------\n",
      "Input sentence: No todo estudiante tiene un diccionario.\n",
      "Dataset translation: \tNot every student has a dictionary.\n",
      "\n",
      "Model output: I haven't seen the book a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy cerrando mi tienda.\n",
      "Dataset translation: \tI'm closing my store.\n",
      "\n",
      "Model output: I'm still and stop.\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo un caballo blanco.\n",
      "Dataset translation: \tI've got a white horse.\n",
      "\n",
      "Model output: I have a book a lot.\n",
      "-----------------------------------------\n",
      "Input sentence: Debemos cumplir sus órdenes.\n",
      "Dataset translation: \tWe must execute his orders.\n",
      "\n",
      "Model output: We must be a lot of the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Qué será, será.\n",
      "Dataset translation: \tWhatever will be, will be.\n",
      "\n",
      "Model output: How looks to school.\n",
      "-----------------------------------------\n",
      "Input sentence: No parece alegrarse de vernos.\n",
      "Dataset translation: \tHe doesn't look happy to see us.\n",
      "\n",
      "Model output: It seent to stay a lot the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Lo firmaré mañana.\n",
      "Dataset translation: \tI'll sign it tomorrow.\n",
      "\n",
      "Model output: I'll come to Tom.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu equipo de fútbol favorito?\n",
      "Dataset translation: \tWhat's your favorite soccer team?\n",
      "\n",
      "Model output: What's your favorite to the book?\n",
      "-----------------------------------------\n",
      "Input sentence: Tu ayuda nos va a ahorrar mucho trabajo.\n",
      "Dataset translation: \tYour help will save us a lot of work.\n",
      "\n",
      "Model output: Your father is a lot of the book to do.\n",
      "-----------------------------------------\n",
      "Input sentence: El niño se ensució las manos.\n",
      "Dataset translation: \tThe boy got his hands dirty.\n",
      "\n",
      "Model output: The boy is a lot of the car.\n",
      "-----------------------------------------\n",
      "Input sentence: Usted debe ser el nuevo profesor.\n",
      "Dataset translation: \tYou must be the new teacher.\n",
      "\n",
      "Model output: You must be a little to the back.\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quién se robó mi canasto con la carne?\n",
      "Dataset translation: \tWho stole my basket with the meat?\n",
      "\n",
      "Model output: Who took the book and stary the back?\n",
      "-----------------------------------------\n",
      "Input sentence: No estaba manejando tan rápido.\n",
      "Dataset translation: \tI wasn't driving all that fast.\n",
      "\n",
      "Model output: I wasn't be a little to do.\n",
      "-----------------------------------------\n",
      "Input sentence: Están muy lejos.\n",
      "Dataset translation: \tThey are very far away.\n",
      "\n",
      "Model output: They're very car.\n",
      "-----------------------------------------\n",
      "Input sentence: Ella hizo un viaje a Europa el mes pasado.\n",
      "Dataset translation: \tShe made a trip to Europe last month.\n",
      "\n",
      "Model output: She did a little and start the back.\n",
      "-----------------------------------------\n",
      "Input sentence: No tengo tiempo para juegos.\n",
      "Dataset translation: \tI don't have time for games.\n",
      "\n",
      "Model output: I have no see to stay the back.\n",
      "-----------------------------------------\n",
      "Input sentence: Compré esta cámara por 25.000 yenes.\n",
      "Dataset translation: \tI bought this camera for 25,000 yen.\n",
      "\n",
      "Model output: I bought the story and stop to Tom.\n"
     ]
    }
   ],
   "source": [
    "test_predictions(train_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model in Core ML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_enc_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "coreml_enc_lstm = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")\n",
    "coreml_enc_out, _, _ = coreml_enc_lstm(coreml_enc_in)\n",
    "\n",
    "coreml_encoder_model = Model(coreml_enc_in, coreml_enc_out)\n",
    "coreml_encoder_model.output_layers = coreml_encoder_model._output_layers\n",
    "\n",
    "inf_encoder.save_weights(\"Es2EnCharEncoderWeights.h5\")\n",
    "coreml_encoder_model.load_weights(\"Es2EnCharEncoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**后面的内容因为训练时的所用环境问题没法及时运行，我也不行改动太多原notebook代码，移步`convert_model_myself.ipynb`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.functional.Functional'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convert() got an unexpected keyword argument 'input_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-388581045189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoreml_encoder_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m coreml_encoder = coremltools.converters.convert(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcoreml_encoder_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"encodedSeq\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: convert() got an unexpected keyword argument 'input_names'"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "\n",
    "coreml_encoder = coremltools.converters.convert(\n",
    "    coreml_encoder_model,\n",
    "    input_names=\"encodedSeq\",\n",
    "    output_names=\"ignored\")\n",
    "\n",
    "coreml_encoder.save(\"Es2EnCharEncoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_dec_in = Input(shape=(None, out_vocab_size))\n",
    "\n",
    "coreml_dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "coreml_dec_lstm_out, _, _ = coreml_dec_lstm(coreml_dec_in)\n",
    "coreml_dec_dense = Dense(out_vocab_size, activation=\"softmax\")\n",
    "coreml_dec_out = coreml_dec_dense(coreml_dec_lstm_out)\n",
    "\n",
    "coreml_decoder_model = Model(coreml_dec_in, coreml_dec_out)\n",
    "coreml_decoder_model.output_layers = coreml_decoder_model._output_layers\n",
    "\n",
    "inf_decoder.save_weights(\"Es2EnCharDecoderWeights.h5\")\n",
    "coreml_decoder_model.load_weights(\"Es2EnCharDecoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 16:30:14.829675: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-12-17 16:30:14.842193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 113 nodes (60), 133 edges (69), time = 2.493ms.\n",
      "  function_optimizer: Graph size after: 113 nodes (0), 133 edges (0), time = 1.399ms.\n",
      "Optimization results for grappler item: while_body_3422\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "Optimization results for grappler item: while_cond_3421\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2021-12-17 16:30:14.935392: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-12-17 16:30:14.963415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 71 nodes (-8), 81 edges (-11), time = 12.136ms.\n",
      "  dependency_optimizer: Graph size after: 57 nodes (-14), 63 edges (-18), time = 1.272ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 1.235ms.\n",
      "  constant_folding: Graph size after: 57 nodes (0), 63 edges (0), time = 2.541ms.\n",
      "  dependency_optimizer: Graph size after: 57 nodes (0), 63 edges (0), time = 0.702ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.127ms.\n",
      "Optimization results for grappler item: while_body_3422\n",
      "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 1.164ms.\n",
      "  dependency_optimizer: Graph size after: 44 nodes (-6), 44 edges (-6), time = 0.341ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.032ms.\n",
      "  constant_folding: Graph size after: 44 nodes (0), 44 edges (0), time = 0.563ms.\n",
      "  dependency_optimizer: Graph size after: 44 nodes (0), 44 edges (0), time = 0.263ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.033ms.\n",
      "Optimization results for grappler item: while_cond_3421\n",
      "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.521ms.\n",
      "  dependency_optimizer: Graph size after: 13 nodes (-1), 3 edges (-1), time = 0.121ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.039ms.\n",
      "  constant_folding: Graph size after: 13 nodes (0), 3 edges (0), time = 0.23ms.\n",
      "  dependency_optimizer: Graph size after: 13 nodes (0), 3 edges (0), time = 0.076ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.008ms.\n",
      "\n",
      "2021-12-17 16:30:15.217323: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-12-17 16:30:15.233233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 113 nodes (60), 133 edges (69), time = 2.862ms.\n",
      "  function_optimizer: Graph size after: 113 nodes (0), 133 edges (0), time = 1.502ms.\n",
      "Optimization results for grappler item: while_body_4106\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "Optimization results for grappler item: while_cond_4105\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2021-12-17 16:30:15.324390: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-12-17 16:30:15.351348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 71 nodes (-8), 81 edges (-11), time = 13.797ms.\n",
      "  dependency_optimizer: Graph size after: 57 nodes (-14), 63 edges (-18), time = 1.492ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.547ms.\n",
      "  constant_folding: Graph size after: 57 nodes (0), 63 edges (0), time = 1.656ms.\n",
      "  dependency_optimizer: Graph size after: 57 nodes (0), 63 edges (0), time = 0.665ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.118ms.\n",
      "Optimization results for grappler item: while_body_4106\n",
      "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 0.743ms.\n",
      "  dependency_optimizer: Graph size after: 44 nodes (-6), 44 edges (-6), time = 0.284ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.024ms.\n",
      "  constant_folding: Graph size after: 44 nodes (0), 44 edges (0), time = 0.494ms.\n",
      "  dependency_optimizer: Graph size after: 44 nodes (0), 44 edges (0), time = 0.237ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.029ms.\n",
      "Optimization results for grappler item: while_cond_4105\n",
      "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.271ms.\n",
      "  dependency_optimizer: Graph size after: 13 nodes (-1), 3 edges (-1), time = 0.083ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.01ms.\n",
      "  constant_folding: Graph size after: 13 nodes (0), 3 edges (0), time = 0.138ms.\n",
      "  dependency_optimizer: Graph size after: 13 nodes (0), 3 edges (0), time = 0.069ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.007ms.\n",
      "\n",
      "Running TensorFlow Graph Passes: 100%|███████| 5/5 [00:00<00:00, 14.97 passes/s]\n",
      "Converting Frontend ==> MIL Ops:   0%|                 | 0/59 [00:00<?, ? ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|█████| 14/14 [00:00<00:00, 21877.89 ops/s]\u001b[A\n",
      "\n",
      "Converting Frontend ==> MIL Ops:   0%|                 | 0/40 [00:00<?, ? ops/s]\u001b[AWARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████| 40/40 [00:00<00:00, 2517.17 ops/s]\n",
      "\n",
      "Converting Frontend ==> MIL Ops: 100%|█████| 14/14 [00:00<00:00, 15505.74 ops/s]\u001b[A\n",
      "\n",
      "Converting Frontend ==> MIL Ops:   0%|                 | 0/40 [00:00<?, ? ops/s]\u001b[AWARNING:root:Input ls elem type unknown. Override with <class 'coremltools.converters.mil.mil.types.type_tensor.tensor.<locals>.tensor'>\n",
      "Converting Frontend ==> MIL Ops: 100%|██████| 40/40 [00:00<00:00, 2311.71 ops/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|███████| 59/59 [00:00<00:00, 257.72 ops/s]\n",
      "Running MIL Common passes: 100%|██████████| 33/33 [00:00<00:00, 812.41 passes/s]\n",
      "Running MIL Clean up passes: 100%|█████████| 8/8 [00:00<00:00, 1054.87 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops:   0%|           | 0/78 [00:00<?, ? ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██| 1/1 [00:00<00:00, 2651.27 ops/s]\u001b[A\n",
      "\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|█| 24/24 [00:00<00:00, 493.30 ops/s]\u001b[A\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|█| 78/78 [00:00<00:00, 1138.34 ops/s\n"
     ]
    }
   ],
   "source": [
    "coreml_decoder = coremltools.converters.convert(\n",
    "    coreml_decoder_model,\n",
    "    input_names=\"encodedChar\",\n",
    "    output_names=\"nextCharProbs\")\n",
    "\n",
    "coreml_decoder.save(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weights to 16bit floats. This shouldn't hurt performance much, if at all, and it reduces the app's download size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.models.neural_network import quantization_utils\n",
    "\n",
    "def convert_to_fp16(mlmodel_filename):\n",
    "    model_fp32 = coremltools.models.MLModel(mlmodel_filename)\n",
    "    spec_16bit = quantization_utils.quantize_weights(model_fp32, nbits=16)\n",
    "    coremltools.utils.save(spec_16bit, f\"{mlmodel_filename}16Bit.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_fp16(\"Es2EnCharEncoder.mlmodel\")\n",
    "convert_to_fp16(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the maps so you can transform text to and from ints. You'll need them later in the iOS app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"esCharToInt.json\", \"w\") as f:\n",
    "    json.dump(in_token2int, f)\n",
    "with open(\"intToEnChar.json\", \"w\") as f:\n",
    "    json.dump(out_int2token, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
